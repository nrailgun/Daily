\documentclass{ctexart}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[]{algorithm2e}

\bibliographystyle{plain}

\title{深度学习分布式计算框架 MXNet}
\author{吴俊宇 15212880}

\begin{document}

\date{}
\maketitle
\tableofcontents
\pagebreak

\section{简介}

深度学习在是最近几年备受关注的话题，也确实取得了非常巨大的成就。在人工智能的许多领域，
特别是计算机视觉、自然语言处理等问题中，深度学习都取得了出了惊人的成就。然而，深度学习
并不是银弹，深度学习的其中一个致命伤就是昂贵的计算代价。

许多的网络的训练与计算代价都非常昂贵，有一些需要数周来使得网络收敛，有一些甚至更长。随着
研究的进行，网络的复杂度和数据的规模还在继续攀升。ImageNet 挑战赛（一个计算机视觉领域的
著名的挑战赛）最近几年的冠军，都使用了非常深的网络结构（深度可能到达数百层）；另一方面，
在大数据时代，数据越来越多，规模超越了 TB 级别，达到了 PB 级别。数以千亿计的浮点运算，单个计算机
早已不堪重负。

研究人员尝试使用 GPU 进行并行计算，在一段时间内，确实计算效率大大提升，缓解了很多问题。
然而时期并不是如此简单就结束，数据规模和网络复杂度还在增加，后来，即使是 NVidia Titan X 这样
的强大 GPU 也无法处理，这个时候，确实需要一个分布式多设备深度学习计算框架。

陈天奇和他的小组 DMLC 设计了一个名为 MXNet 的深度学习框架 \cite{this-paper}。这个框架接口灵活，设计优雅，
计算高效，并且最重要的是，他支持多 GPU 和多机分布式计算。

\section{与现有框架的比较}

在深度学习开始受到关注之后，许多黑客开始设计通用的深度学习框架。其中比较著名的有 Caffe，Torch，
TensorFlow 和 MXNet。

\vfill
\begin{tabular}{|c|c|c|c|}
	\hline \rule[-2ex]{0pt}{5.5ex} System & Core language & Devices & Distributed \\ 
	\hline \rule[-2ex]{0pt}{5.5ex} Caffe & C++ & GPU &  \\ 
	\hline \rule[-2ex]{0pt}{5.5ex} Torch & Lua & GPU / FPGA &  \\ 
	\hline \rule[-2ex]{0pt}{5.5ex} TensorFlow & C++ & GPU & $\checkmark$ \\ 
	\hline \rule[-2ex]{0pt}{5.5ex} MXNet & C++ & GPU & $\checkmark$ \\ 
	\hline 
\end{tabular}
\vfill

Caffe 是比较早的深度学习框架，也是最著名，最流行的深度学习框架之一，不过它的设计上存在一些
弊病，并且他并不支持分布式计算（到 2016 年 Caffe 提供了单机多 GPU 的支持）。TensorFlow 是 Google
提供的开源项目，可能是最简单易用，功能强大的深度学习框架，并且具有非常强大的分布式计算支持，
美中不足在于其极为糟糕的性能，不足 Caffe 的 $\frac 1 2$。

MXNet 可能是一个较为折中的解决方案。MXNet 接口灵活，设计优雅，计算高效，支持多 GPU 和多机分布式计算。

\section{MXNet 设计架构}

MXNet 的设计极为简洁优雅。MXNet 主要组件包含：

\begin{description}
	\item [Core：] DMLC 小组设计的通用组件，包含一些基本的功能和组件；
	\item [MShadow / CUDA：] 一个基于 CUDA 的计算库，用于隐藏 GPU / CPU 计算的细节；
	\item [PS-lite：] 一个分布式的参数服务器；
	\item [MXNet：] MXNet 程序核心逻辑。
\end{description}

MXNet 核心逻辑直接基于三大组件：

\begin{description}
	\item [符号表达式] 符号表达式提供张量运算，用于简单抽象地构建网络；
	\item [NDArray] 提供真正运算的能力，隐藏了多 GPU 和 CPU 的计算细节，不仅性能优良，而且避免暴露内部
	实现；
	\item [KVStore] 参数服务器，一个分布式的键值对存储器，用来在多 GPU 和多机器之间实现数据同步。KVStore
	提供了 push 和 pull 的基本功能，使得网络的分布式计算可以简单抽象为如下的伪代码。
	\begin{lstlisting}
	while (1) {
		kv.pull(net.w);
		net.forward_backward();
		kv.push(net.g);
	}
	\end{lstlisting}
\end{description}

\section{参数服务器}

参数服务器（Parameter server）由 Li Mu 等人在 2014 年提出所提出 \cite{communication} \cite{scaling} 。他们提出了一种
分布式的深度学习计算系统架构，认为深度学习的集群由一个服务器组和若干工人组所组成。服务器用于维护和保存神经网络
中的参数，而工人则负责前向计算和反向传播计算导数，与服务器通信并升级参数。

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{pics/ps-arch}
\caption{参数服务器架构}
\label{fig:ps-arch}
\end{figure}

如图 \ref{fig:ps-arch} 所示，参数服务器维护着整个网络的参数，每次迭代中，工人向服务器索取参数，利用参数进行前向
与后向的计算，再将结算结果（前向结果及后向导数）回传服务器，服务器进行相应的参数计算。

\section{并行模型与同步模型}

MXNet 提供了两种不同的并行模型和两种不同的同步模型。并行模型有数据并行和模型并行两种，同步模型有同步和异步两种。

这里简单介绍一下梯度下降算法，梯度下降算法是一个一阶优化方法，用于寻找函数中的局部最优，神经网络中常常
用于优化网络参数，其变种包括随机梯度下降。梯度下降数学表示为

$$
W_i^{n+1} = W_i^{n} - \gamma_n \frac {\partial J} {\partial W_i^{n}} 
$$
其中 $J = \sum_j F(W, X_j)$ 为网络优化目标，$W_i^{n}$ 是网络权重，$n$ 是网络的迭代轮数。

\subsection{并行模型}

\subsubsection{数据并行}
数据并行的思想着实非常简单，它被设计出来主要是为了加速神经网络计算。
由于神经网络中，$J = \sum_j F(W, X_i)$ 与 $J = \sum_j F(W, X_j)$ 的计算互相独立，
所以可以同时进行计算。数据并行仅仅是将数据进行划分，多个计算单元分别计算自己那一部分的数据。

而参数的升级，MXNet 提供了 3 中方法：
\begin{itemize}
	\item LOCAL\_UPDATE\_CPU
	\item LOCAL\_ALLREDUCE\_CPU
	\item LOCAL\_ALLREDUCE\_DEVICE
\end{itemize}
分别在 CPU 上或者 GPU 上进行不同级别的导数升级，数据规模越大，越多的操作应该在 GPU 上进行。

\subsubsection{模型并行}
不同于数据并行，模型并行不太直观，设计出来主要是为了容纳超大型的神经网络结构。
模型并行是近几年比较受关注的话题。

某些超大型的神经网络，结构可能非常巨大，在单一一个计算节点可能无法容纳。在模型并行中，巨大的网络
以层为单位，进行分割，单个计算节点容纳网络的一个或者若干个层，分别计算，并传递结果，如图 \ref{fig:model-param}
所示。

\begin{figure}
\centering
\includegraphics[width=0.3\linewidth]{pics/model-param}
\caption{模型并行计算}
\label{fig:model-param}
\end{figure}

\subsection{同步模型}

多个计算节点需要保持某种程度的同步，否则计算结果很可能出错，或者难以理解。

\subsubsection{同步}
同步的梯度下降语义上和单机版本一样。每一次迭代中，服务器会等待所有计算节点计算完毕，再进行导数的求和与升级。
因此，算法可以简单的用如下伪代码代替：

\begin{algorithm}[H]
	initialize $t \leftarrow 0$ \;
	\While {$t < $ num-iterations} {
		\For {each worker $i$}{
			compute-gradient(i)\;
		}
		server-update-weight()\;
		wait-all-finished()\;
	}
	\caption{Synchronized multi-node gradient descent}
\end{algorithm}

\subsubsection{异步}

异步在语义上与单机版本的梯度下降完全不同，他不会等待工人完成计算任务，只要有任何一个工人完成其任务，服务器便进行
相应的梯度升级工作。用伪代码来表示算法如下：

\begin{algorithm}[H]
	initialize $t \leftarrow 0$ \;
	\While {$t < $ num-iterations and Receive-grad(grad)} {
		$ w_k -= eta(t) \times grad$\;
		$t = t + 1$\;
	}
	\caption{Asynchronized multi-node gradient descent}
\end{algorithm}

但是算法同时导致了数据不一致的问题，由于节点计算速度不一致，部分节点可能在较旧的参数上进行计算，导致得到错误的
计算结果。

\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{pics/delay}
\caption{异步计算导致数据不一致}
\label{fig:delay}
\end{figure}

幸运的是，虽然听起来不可思议，但是异步计算存在理论上的收敛 \cite{scaling}。证明过程比较繁杂，不做细述。
不过就算如此，MXNet 社区不太建议使用该方法，虽然可能提高计算速度，但是网络的难以预测性和不稳定性进一步增加，
可能使得网络排错很困难。

\subsection{多级别同步}

单个计算机可能包括多个计算节点（CPU 和多个 GPU）。考虑到不同节点之间通信速度存在巨大差异，比如 GPU 和 CPU 通信
开销可能小于机器之间的网络通信开销，MXNet 的同步模型是 2 级的，在机器内和机器间使用了不同的同步模型和模型参数。
大体结构如图 \ref{fig:lv2sync} 所示。

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{pics/lv2sync}
\caption{2 级同步机制}
\label{fig:lv2sync}
\end{figure}

\section{代码例子}

本文附带了一个代码例子，在文件夹 DSProj 中，是我学习时候练习所留下的代码，作为简单示例。请参考附带的
README.markdown 并运行。

\section{结语}

分布式计算一直是一个长盛不衰的话题，时至今日分布式计算任然蓬勃发展。MXNet 是分布式计算在近年炙手可热
的深度学习领域的一个重要尝试。分布式计算在今日，与大数据与深度学习结合，发挥重要作用。

\pagebreak
\bibliography{MXNet.bib}

\end{document}