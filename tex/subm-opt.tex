\documentclass{ctexart}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage[]{algorithm2e}

\bibliographystyle{plain}

\title{数据挖掘中的组合优化 —— 利用次模函数挖掘有趣项集}
\author{吴俊宇 15212880}

\newcommand{\scri}[0]{\mathcal{I}}

\begin{document}

\date{}
\maketitle
\tableofcontents
\pagebreak

\section{综述}

我主要的研究方向是计算机视觉和深度学习，偶尔涉及数据挖掘。组合优化问题是在有穷离散的解空间中，
寻找最优解 \cite{cop-wiki}，属于优化问题。组合优化在许多领域有重要应用，比如人工智能、机器学习，和软件工程。

频繁项集挖掘（Frequent itemset mining）是数据挖掘中一个很流行的技术，用于探索数据之间的内在关联。
特别的，对于市场购物篮问题，每个数据点，也称为事务（Transaction），是一个数据项的集合。频繁项集挖掘的
目标是，在事务数据库中，寻找一些频繁项集，它们能表示一些数据的共性 \cite{hjw-book}。
由于数据项是有限且离散的，所以可能的组合也是有限且离散的，寻找这样的组合属于组合优化问题。

从统计角度出发，单纯的频繁项集挖掘存在一些问题，例如有些项集频繁是由于数据项本身频繁，数据项之间却
没有关联，或者数据项集过大，冗余，难以理解。Jaroslav Fowkes 提出，出现这种问题的原因是：解决了错误的问题。
用户并不关心频繁的项集，用户关心的是，“有趣”的项集，可以最有效描述事务数据库的项集\cite{this-paper}。
文章提出，挖掘“有趣”项集，也就是在一个简单但是自然的事务概率模型中最有效的项集。有趣项集可以
通过结构化 EM 方法推导 \cite{em-book}。本文旨在介绍 Jaroslav Fowkes 提出的算法，结合组合优化方法，解决数据挖掘问题。

\section{有趣项集挖掘}

本节形式化“识别一个有趣频繁项集集合是否对研究事务数据库有效”的问题。
首先定义一些前置的概念和注记。数据项 $i$ 是论域 $U = \{1, 2, \dots, n\}$ 的元素，事务 $X$ 是 $U$ 的子集，
项集 $S$ 是项 $i$ 的集合。有趣项集的集合 $\mathcal I$ 是我们的目标，是 $U$ 的的幂集的子集。另外，
我们称项集 $S$ \textit{支持}事务 $X$ 如果 $S \subset X$。

\subsection{产生模型}

我们提出一个简单的模型从有趣项集来产生事务数据库。模型的参数是一个有趣项集的集合 $\scri$ 和每个有趣项集
$S \in \scri$ 对应的伯努利概率 $\pi_S$。分别地对于数据库中每个事务 $X$，
\begin{enumerate}
	\item 对于每个 $S \in \scri$，独立决定是否在事务中包含 $S$
	$$
	z_S \sim \mathrm{Bernoulli}(\pi_S)
	$$
	\item 将事务设置为上一步选中的项集中的项的集合
	$$
	X = \bigcup \left\{ i \in S | S \in \scri, z_S = 1 \right\}
	$$
\end{enumerate}
注意模型允许一个项从多个项集中产生多次。

\subsection{递推}

给定项集集合 $\scri$，让 $z$ 和 $\pi$ 成为每个项集 $S$ 的 $z_S$ 和 $\pi_S$ 的向量（数组），
其中项集 $S \in \scri$。
假定 $z$ 和 $\pi$ 是完全确定的，因为 $z_S$ 服从伯努利分布，显然从产生模型可以得到产生事务 $X$ 的概率为
\begin{equation}
\label{3.1}
p(X, z \mid \pi) = \prod_{S \in \scri} \pi_S^{z_S} (1 - \pi_S)^{1 - z_S}
\text{ if } X = \bigcup_{z_S = 1} S \text{, otherwise } 0
\end{equation}
假定隐变量  $\pi$ 已知，那么可以是用极大似然估计 MLE 从事务 $X$ 递推得到 $z$。从式子 \ref{3.1} 显然可以
得到，极大似然的解便是极大后验分布 $p(z \mid X, \pi)$

\begin{equation}
\label{3.2}
\max_z \prod_{S \in \scri} \pi_S^{z_S} (1 - \pi_S)^{1 - z_S}
\end{equation}
$$
s.t. X = \bigcup \left\{ i \in S | S \in \scri, z_S = 1 \right\}
$$

取对数并重写式 \ref{3.2}，我们得到更加标准的形式
\begin{equation}
\label{3.3}
\max_z \sum_{S \in \scri} z_S \ln \left( \frac{\pi_S}{1 - \pi_S} \right) + \ln \left(1 - \pi_S \right)
\end{equation}
$$
s.t. \sum_{S \mid i \in S} z_S \geq 1 \ \forall i \in X
$$
$$
z_S \in \{0, 1\} \ \forall S \in \scri
$$

这是一个加权集覆盖问题 \cite{weighted-set-cover}，其中权重 $w_S \in \mathbb{R} $ 由下式给出
$$
w_S := \ln\left( \frac{\pi_S}{1 - \pi_S} \right)
$$
这是一个 NP 难问题，直接求解在实践中是不符合实际的。有一点非常重要，必须要注意到，加权集覆盖问题
是给定次模（\textit{Submodular}）约束极大化线性函数的特例，我们可以将之公式化 \cite{young}。给出
支持事务的有趣项集的集合 $\tau$
\begin{equation}
\label{3.4}
\tau := \left\{ S \in \scri \mid S \subset X \right\}
\end{equation}
对于每个 $S \in \tau$ 一个实数权重 $w_S$，和一个非递减次模函数（\textit{submodular function}）
$f: 2^\tau \to \mathbb{R}$，目标是为了找到一个最大总权重的 $C \subset \tau$，使得 $f(C) = f(\tau)$，
并且最大化 $\sum_{S \in C} w_S$。我们简单定义 $f(C)$ 为$C$ 中项的数目，即 $f(C) := | \bigcup_{S \in C} S |$。
注意到，根据构造，$f(\tau) = | X | $。

因此，我们得已使用次模函数贪心近似算法近似求解问题 \ref{3.3}。贪心算法通过反复选取项集 $S$，使得
$S$ 最大化 $w_S$ 除以尚未被选取项集覆盖的项的数目的值，构造一个 $C$。

\begin{algorithm}[H]
	\KwData{Transaction $X$, set of itemsets $\tau$ , weights $w$}
	initialize $C \leftarrow \emptyset$ \;
	\While {$f(C) \neq |X| $} {
		Choose $S \in \tau$ maximizing $\frac{w_S}{ f(C \cup {S}) - f(C) }$ \;
		$C \leftarrow C \cup {S}$ \;
	}
\caption{Greedy Weighted Set Covers}
\end{algorithm}

已经有人证明，该类问题上，贪心算法可以达到 $\ln |X| + 1$ 近似率 \cite{chivatal}，并且，Feige 的不可近似性定义已经证明
这就是最优的可能近似了 \cite{feige}。贪心算法的运行时复杂度是 $O(|X| |\tau|)$，通过优先队列改善算法，可以使得算法优化
到 $O(|X| \log |\tau|)$。

\subsection{学习}

给定一个项集的集合 $\scri$，现在考虑 $z$ $\pi$ 在模型中都未知的情况。这种情况下我们可以使用强 EM 算法来做参数估计。
强 EM 算法在我们的问题中，仅仅是递推算法顶部的一个层。假定如同式 \ref{3.4} 定义，
有 $m$ 个事务 $X^{(1)}, X^{(2)}, \dots, X^{(m)} $ 和支持项集的集合
$\tau^{(1)}, \tau^{(2)}, \dots, \tau^{(m)} $，那么强 EM 边如算法 \ref{algo2} 所示。初始化 $\pi$ 的一个简单选择是是用数据集中项集的支持。

\begin{algorithm}[H]
	\KwData{Set of itemsets $\scri$ and initial estimates $\pi^{(0)}$}
	initialize $k \leftarrow 0$ \;
	
	$k \leftarrow k + 1$ \;
	E-step: $\forall X^{(j)}$ solve formula \ref{3.3} using algorithm 1 to obtain $z_S^{(j)} \forall S \in \tau_j$\;
	
	M-step: $\pi_S^{(k)} \leftarrow \frac 1 m \sum_{j=1}^m z_S^{(j)} \forall S \in \scri$
	
	\While {$ \| \pi^{(k-1)} - \pi^{(k)} \| \ge \epsilon $} {
		$k \leftarrow k + 1$ \;
		E-step: $\forall X^{(j)}$ solve formula \ref{3.3} using algorithm 1 to obtain $z_S^{(j)} \forall S \in \tau_j$\;
		
		M-step: $\pi_S^{(k)} \leftarrow \frac 1 m \sum_{j=1}^m z_S^{(j)} \forall S \in \scri$
	}
	return $\scri$, $\pi^{(k-1)}$\;
	\label{algo2}
	\caption{Hard Expectation Maximization}
\end{algorithm}

\subsection{推导新项集}

使用结构化 EM 算法 \cite{friedman} 来推导新项集。我们添加候选项集 $S'$ 到 $\scri$ 中，如果添加之后式 \ref{3.3}
中在各个事务上最优值的平均值 $\overline{p}$ 得到改善，那么就将这个候选集添加到 $\scri$ 中。
给定 $X^{(1)}, X^{(2)}, \dots, X^{(m)}$，项集的集合 $\scri$ 和对应的概率，结构化 EM 算法的迭代如图 \ref{fig:algo3} 所示。
实际使用中，我们存储被算法 3 否决的候选集，并且在运行算法后半部分之前，检查每一个潜在候选集是否存在，以提高
计算效率。

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{pics/algo3}
	\caption{Structural EM (one iteration)}
	\label{fig:algo3}
\end{figure}

\subsection{产生候选项集}
结构化 EM 算法需要一个方法来产生新的用来添加到有趣项集集合 $\scri$ 中的候选项集 $S'$。一个可能的方案是是用
Apriori 算法来从单例递归地提供可能的项集，不过这可能计算效率不太好。因此，我们采用了图 \ref{fig:algo4} 的算法，
递归地将 $\scri$ 中的有趣项集与 Hightest support first 进行组合。

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{pics/algo4}
	\caption{Support-weightedItemset Combination}
	\label{fig:algo4}
\end{figure}

\subsection{挖掘有趣项集}

完整的有趣项集挖掘算法如算法 5 所示。注意参数优化步骤（算法2）不需要每一次迭代都执行。
事实上如果在优化参数之前，多提供若干个候选项集将使得算法更加高效。我们根据有趣度对项集进行排序，
形式化的定义有趣度如下：

在算法 5 中提取的项集 $S \in \scri$ 的有趣度定义如下
$$
\mathrm{int}(S) = \frac { \sum_{j=1}^{m} z_S^{(j)} }{ supp(S) }
$$
值域为从 0（非常无趣） 到 1（非常有趣） 之间。

\begin{algorithm}[H]
	\KwData{Database transactions}
	initialize $\scri$ with singletons and $\pi$ with their supports \;
	build EIM-tree from transaction database \;
	\While {not converged} {
		add itemsets to $\scri$, $\pi$ using algorithm 3 \;
		optimize parameter for $\scri$ , $\pi$ for algorithm 2 \;
	}
	return $\scri$, $\pi$ \;
	\label{algo5}
	\caption{Interesting itemset Miner (IIM)}
\end{algorithm}

\section{实验}
Jaroslav Fowkes 在真实事务数据集进行了测试。他们用 IIM 在 ICDM 数据集 \cite{DeBie} 上进行了 $1000$ 次迭代，并和
FPGrowth 进行了比较。图 \ref{fig:tab1} 比较了有趣项集和频繁项集。我们可以清楚地看到，有趣项集告诉了我们更多的
信息。

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{pics/tab1}
\caption{IIM 和 FPGrowth 找到的大小为 2 的 Top 10 项集}
\label{fig:tab1}
\end{figure}

\section{结论}
文中提出了一种与传统频繁项集不同的方法，提取“有趣”项集。有趣项集提供了更多的信息，
避免了频繁项集中无相关和繁琐无意义的问题。

\pagebreak
\bibliography{subm-opt.bib}

\end{document}